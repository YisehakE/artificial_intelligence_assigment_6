{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence\n",
    "# 464/664\n",
    "# Assignment #6\n",
    "\n",
    "## General Directions for this Assignment\n",
    "\n",
    "00. We're using a Jupyter Notebook environment (tutorial available here: https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html),\n",
    "01. Read the entire notebook before beginning your work, \n",
    "02. Output format should be exactly as requested (it is your responsibility to make sure notebook looks as expected on Gradescope),\n",
    "03. Each helper function should be preceeded by documentation (Markdown cell), \n",
    "04. Each helper function (not `train`) should be followed by three assert-style unit tests,\n",
    "05. **Do not use any AI/ML libraries, packages, such as pandas, scikit (numpy is fine)**\n",
    "06. Functions should do only one thing,\n",
    "07. Check submission deadline on Gradescope, \n",
    "08. Rename the file to Last_First_assignment_6, \n",
    "09. Submit your notebook (as .ipynb, not PDF) using Gradescope, and\n",
    "10. Do not submit any other files.\n",
    "\n",
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "For this assignment we will implement a Decision Tree using the ID3 Algorithm. The goal is classify a mushroom as either edible ('e') or poisonous ('p'). Dataset has been uploaded to Canvas. In case you'd like to learn more about it, here's the link to the repo: https://archive.ics.uci.edu/dataset/73/mushroom. \n",
    "\n",
    "\n",
    "Our  Decision Tree pipeline is as follows:\n",
    "\n",
    "\n",
    "1) `cross_validate` will take data (supplied as folds using 10 fold cross validation) and do the following:\n",
    "* For each setting of depth limit (the hyperparameter in decision trees, including 0)\n",
    "* * and for each fold of data\n",
    "* * * use `create_train_test` to split current fold into train and test\n",
    "* * * call `train` to build and return a decision tree, \n",
    "* * * call `classify` to use the tree to get classifications,\n",
    "* * * call `evaluate` to compare classifications to the actual answers (ground truth),\n",
    "* * * Print the performance for that fold\n",
    "* * Summarize the performance for that depth limit over all folds using `get_stats`\n",
    "\n",
    "\n",
    "2) `pretty_print_tree(tree)` will print what the tree looks like when using the **entire** data set (no train/test split) with depth limit set to None.\n",
    "\n",
    "\n",
    "All the code in this pipeline has been provided, except for a working `train` function. The `train` function currently returns a hard-coded tree from our lecture. Don't do that. Use ID3 to build your tree and use the depth limit to stop. When you're train function is complete, it should work for the lecture data, and mushrooms. Although `train` is terrible right now, pay attention to how the tree is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict, Tuple, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"note\"></a>\n",
    "\n",
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <strong>Note</strong>\n",
    "    <p>\n",
    "        Let's start with our example from the 06-Nov lecture. Target variable is Safe?, which can be yes or no. Anything *_lecture refers to the dataset we walked through in class.  \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lecture = [['round','large','blue','no'],\n",
    "['square','large','green','yes'],\n",
    "['square','small','red','no'],\n",
    "['round','large','red','yes'],\n",
    "['square','small','blue','no'],\n",
    "['round','small','blue','no'],\n",
    "['round','small','red','yes'],\n",
    "['square','small','green','no'],\n",
    "['round','large','green','yes'],\n",
    "['square','large','green','yes'],\n",
    "['square','large','red','no'],\n",
    "['square','large','green','yes'],\n",
    "['round','large','red','yes'],\n",
    "['square','small','red','no'],\n",
    "['round','small','green','no']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['round', 'large', 'blue', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(data_lecture[0]) # a record of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_names_lecture = ['shape', \n",
    "                      'size', \n",
    "                      'color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_folds\"></a>\n",
    "## create_folds\n",
    "\n",
    "\n",
    "With n-fold cross validation, we divide our data set into n subgroups called \"folds\" and then use those folds for training and testing. For data set with 100 observations (or records), n set to 10 would have 10 observations in each fold.\n",
    "\n",
    "* **data** List: a list (data_lecture, for instance)\n",
    "* **n** int: number of folds\n",
    "\n",
    "\n",
    "**returns** \n",
    "folds, which is a list of n items, where each item is a list containing a subgroup of xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(data: List, n: int) -> List[List[List]]:\n",
    "    k, m = divmod(len(data), n)\n",
    "    return list(data[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_lecture = create_folds(data=data_lecture, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folds_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(folds_lecture[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['square', 'small', 'red', 'no'], ['round', 'large', 'red', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(folds_lecture[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_train_test\"></a>\n",
    "## create_train_test\n",
    "\n",
    "\n",
    "This function takes the n folds and returns the train and test sets. One of the n folds is used to test, the others are used for training.\n",
    "\n",
    "* **folds** List[List[List]]: see `create_folds`\n",
    "* **index** int: fold index that is used for testing\n",
    "\n",
    "\n",
    "**returns** \n",
    "folds, which is a list of n items, where each item is a list containing a subgroup of xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(folds: List[List[List]], index: int) -> Tuple[List[List], List[List]]:\n",
    "    training = []\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = training + fold\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lecture, test_lecture = create_train_test(folds_lecture, 0) # test data is folds_lecture index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['square', 'small', 'red', 'no'], ['round', 'large', 'red', 'yes'], ['square', 'small', 'blue', 'no'], ['round', 'small', 'blue', 'no'], ['round', 'small', 'red', 'yes'], ['square', 'small', 'green', 'no'], ['round', 'large', 'green', 'yes'], ['square', 'large', 'green', 'yes'], ['square', 'large', 'red', 'no'], ['square', 'large', 'green', 'yes'], ['round', 'large', 'red', 'yes'], ['square', 'small', 'red', 'no'], ['round', 'small', 'green', 'no']]\n"
     ]
    }
   ],
   "source": [
    "print(train_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(test_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lecture, test_lecture = create_train_test(folds_lecture, 1) # test data is folds_lecture index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes'], ['square', 'small', 'blue', 'no'], ['round', 'small', 'blue', 'no'], ['round', 'small', 'red', 'yes'], ['square', 'small', 'green', 'no'], ['round', 'large', 'green', 'yes'], ['square', 'large', 'green', 'yes'], ['square', 'large', 'red', 'no'], ['square', 'large', 'green', 'yes'], ['round', 'large', 'red', 'yes'], ['square', 'small', 'red', 'no'], ['round', 'small', 'green', 'no']]\n"
     ]
    }
   ],
   "source": [
    "print(train_lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['square', 'small', 'red', 'no'], ['round', 'large', 'red', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "print(test_lecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"note\"></a>\n",
    "\n",
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <p>\n",
    "        Let's load the mushroom data.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"parse_data\"></a>\n",
    "## parse_data\n",
    "\n",
    "Opens a file, splits on comma, and shuffles data before returning as a List of list. \n",
    "\n",
    "* **file_name** Str: filename for data\n",
    "\n",
    "\n",
    "**returns** \n",
    "Data as a list of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> List[List]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = [value for value in line.rstrip().split(\",\")]\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mushroom = parse_data(\"agaricus-lepiota.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <strong>Important</strong>\n",
    "    <p>\n",
    "        We're going to move the target column (mushroom edible or poisonous) to the last column to match the lecture's format, where Safe? was at the end.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mushroom = [record[1:]+[record[0]] for record in data_mushroom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8124"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_mushroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'f', 'y', 'f', 'f', 'f', 'c', 'b', 'h', 'e', 'b', 'k', 'k', 'b', 'n', 'p', 'w', 'o', 'l', 'h', 'v', 'd', 'p']\n"
     ]
    }
   ],
   "source": [
    "print(data_mushroom[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_names_mushroom = ['cap-shape',\n",
    "                   'cap-surface',\n",
    "                   'cap-color',\n",
    "                   'bruises?',\n",
    "                   'odor',\n",
    "                   'gill-attachment',\n",
    "                   'gill-spacing',\n",
    "                   'gill-size',\n",
    "                   'gill-color',\n",
    "                   'stalk-shape',\n",
    "                   'stalk-root',\n",
    "                   'stalk-surface-above-ring',\n",
    "                   'stalk-surface-below-ring',\n",
    "                   'stalk-color-above-ring',\n",
    "                   'stalk-color-below-ring',\n",
    "                   'veil-type',\n",
    "                   'veil-color',\n",
    "                   'ring-number',\n",
    "                   'ring-type',\n",
    "                   'spore-print-color',\n",
    "                   'population',\n",
    "                   'habitat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_answers\"></a>\n",
    "## get_answers\n",
    "\n",
    "This function extracts a list of the target values from data. The function assumes the target variable is the last column of the data.\n",
    "\n",
    "* **data** List[List]: The data provided in a list of list format identical to the structure of `data_lecture` or `data_mushroom`\n",
    "\n",
    "\n",
    "**returns** \n",
    "A list of the values of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(data):\n",
    "    return [record[-1] for record in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_answers([]) == []\n",
    "assert get_answers(data_lecture) == ['no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_mode\"></a>\n",
    "## get_mode\n",
    "\n",
    "This function finds the mode of a list of items. \n",
    "\n",
    "* **answers** List: A list of items\n",
    "\n",
    "**returns** \n",
    "The item that appears the most often in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(answers):\n",
    "    count_dict = {}\n",
    "    for answer in answers:\n",
    "        if answer in count_dict:\n",
    "            count_dict[answer] = count_dict[answer] + 1\n",
    "        else:\n",
    "            count_dict[answer] = 1\n",
    "    mode_count = max(count_dict.values())\n",
    "    mode = [k for k, v in count_dict.items() if v == mode_count]\n",
    "    return mode[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_mode(['no', 'no', 'no', 'yes']) == 'no'\n",
    "assert get_mode(['no', 'no', 'yes', 'yes']) == 'no'\n",
    "assert get_mode(['no', 'yes', 'yes', 'yes']) == 'yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_labels\"></a>\n",
    "## get_labels\n",
    "\n",
    "This function extracts the unique labels from the training data. The labels are typically found in the last column of the data, and this function identifies and returns them.\n",
    "\n",
    "* **training_data** (List): A list representing the training data, where each sublist corresponds to a data point.\n",
    "\n",
    "**returns**\n",
    "A list of unique labels present in the last column of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(training_data) :\n",
    "    label_location = len(training_data[0]) - 1\n",
    "    labels = []\n",
    "    for data in training_data:\n",
    "        label = data[label_location]\n",
    "        if label not in labels : labels.append(label)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_training_data = [['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes'], ['square', 'small', 'blue', 'no']]\n",
    "test_labels = ['no','yes']\n",
    "assert get_labels(test_training_data) == test_labels\n",
    "test_training_data = [['round', 'large', 'blue', 'no'],['round', 'large', 'blue', 'yes'],['round', 'large', 'blue', 'N/A']]\n",
    "test_labels = ['no','yes','N/A']\n",
    "assert get_labels(test_training_data) == test_labels\n",
    "test_training_data = [['round', 'large', 'blue', 'yes'], ['square', 'large', 'green', 'yes'], ['square', 'small', 'blue', 'yes']]\n",
    "test_labels = ['yes']\n",
    "assert get_labels(test_training_data) == test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_majority_label\"></a>\n",
    "## get_majority_label\n",
    "\n",
    "This function determines the majority label for a given set of training data. It counts the occurrences of each label in the last column of the data and identifies the label that occurs most frequently. If a single label dominates the entire dataset, it is considered homogeneous.\n",
    "\n",
    "* **training_data** (List): A list representing the training data, where each sublist corresponds to a data point.\n",
    "* **labels** (List): A list of unique labels present in the last column of the training data.\n",
    "\n",
    "**returns**\n",
    "A tuple containing two values:\n",
    "1. A boolean indicating whether the dataset is homogeneous based on the labels.\n",
    "2. If homogeneous, the single label dominating the dataset; otherwise, the label with the maximum occurrence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_majority_label(training_data,labels) :\n",
    "    label_location = len(training_data[0]) - 1\n",
    "    label_map = {label: 0 for label in labels}\n",
    "    num_data = len(training_data)\n",
    "    for data in training_data:\n",
    "        label = data[label_location]\n",
    "        last_labeled = label\n",
    "        label_map[label] = label_map[label] + 1\n",
    "    if label_map[last_labeled] == num_data: return True,last_labeled\n",
    "    max_label = max(label_map, key=lambda r: label_map[r])\n",
    "    return False,max_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_training_data = [['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes'], ['square', 'small', 'blue', 'no']]\n",
    "test_is_homogenous,test_label = get_majority_label(test_training_data,get_labels(test_training_data))\n",
    "assert test_is_homogenous == False\n",
    "assert test_label == \"no\"\n",
    "test_training_data = [['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'no'], ['square', 'small', 'blue', 'no']]\n",
    "test_is_homogenous,test_label = get_majority_label(test_training_data,get_labels(test_training_data))\n",
    "assert test_is_homogenous == True\n",
    "assert test_label == \"no\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_attr_domain\"></a>\n",
    "## get_attr_domain\n",
    "\n",
    "This function extracts the unique values of a specific attribute (column) from the training data. \n",
    "\n",
    "* **training_data** (List): A list representing the training data, where each sublist corresponds to a data point.\n",
    "* **attr_location** (int): The index representing the location of the attribute (column) for which the domain is to be obtained.\n",
    "\n",
    "**returns**\n",
    "A list containing the unique values of the specified attribute in the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attr_domain(training_data,attr_location):\n",
    "    attr_domain = []\n",
    "    for data in training_data:\n",
    "        value = data[attr_location]\n",
    "        if value not in attr_domain: attr_domain.append(value)\n",
    "    return attr_domain\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_training_data = [['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes'], ['square', 'small', 'blue', 'no']]\n",
    "assert get_attr_domain(test_training_data,0) == [\"round\",\"square\"]   \n",
    "assert get_attr_domain(test_training_data,1) == [\"large\",\"small\"]   \n",
    "assert get_attr_domain(test_training_data,2) == [\"blue\",\"green\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_probabilities\"></a>\n",
    "## get_probabilities\n",
    "\n",
    "This function counts occurences of a result in condition of the value in the attribute column\n",
    "\n",
    "* **label_location** (int): The index representing the location of the label (answer) in each data point.\n",
    "* **attr_location** (int): The index representing the location of the attribute for which probabilities are calculated.\n",
    "* **training_data** (List): A list representing the training data, where each sublist corresponds to a data point.\n",
    "* **labels** (List): A list of unique labels present in the label column of the training data.\n",
    "\n",
    "**returns**\n",
    "A tuple containing two dictionaries:\n",
    "1. A nested dictionary (`values`) where each key is an attribute value, and the corresponding value is a dictionary representing label occurrences for that attribute value.\n",
    "2. A dictionary (`sums`) where each key is an attribute value, and the corresponding value is the sum of label occurrences for that attribute value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities(label_location,attr_location,training_data,labels):\n",
    "    attr_domain = get_attr_domain(training_data,attr_location)\n",
    "    values = {value: {label:0 for label in labels} for value in attr_domain}\n",
    "    for data in training_data:\n",
    "        attr_value = data[attr_location]\n",
    "        label = data[label_location]\n",
    "        value_map = values[attr_value]\n",
    "        value_map[label] = value_map[label] + 1\n",
    "    sums = {}\n",
    "    for value in values:\n",
    "        sum = 0\n",
    "        value_map = values[value]\n",
    "        for label in value_map:\n",
    "            sum = sum + value_map[label]\n",
    "        sums[value] = sum\n",
    "    return values,sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_training_data = [['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes'], ['square', 'small', 'blue', 'no']]\n",
    "test_label_location = 3\n",
    "test_attr_location = 2\n",
    "test_labels = ['no','yes']\n",
    "test_probabilities,test_sums = get_probabilities(test_label_location,test_attr_location,test_training_data,test_labels)\n",
    "assert test_sums == {'blue':2,'green':1}\n",
    "assert test_probabilities == {'blue':{'no':2,'yes':0},'green':{'no':0,'yes':1}}\n",
    "test_attr_location = 1\n",
    "test_probabilities,test_sums = get_probabilities(test_label_location,test_attr_location,test_training_data,test_labels)\n",
    "assert test_sums == {'large':2,'small':1}\n",
    "assert test_probabilities == {'large':{'no':1,'yes':1},'small':{'no':1,'yes':0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"calculate_entropy\"></a>\n",
    "## calculate_entropy\n",
    "\n",
    "This function computes the entropy of a set of probabilities given their occurrences and corresponding sums. \n",
    "\n",
    "* **probabilities** (Dict): A nested dictionary where each key is an attribute value, and the corresponding value is a dictionary representing label occurrences for that attribute value.\n",
    "* **sums** (Dict): A dictionary where each key is an attribute value, and the corresponding value is the sum of label occurrences for that attribute value.\n",
    "* **num_items** (int): The total number of items in the dataset.\n",
    "\n",
    "**returns**\n",
    "The entropy value calculated for the set of probabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(probabilities,sums,num_items):\n",
    "    total_entropy = 0\n",
    "    for key in probabilities:\n",
    "        entropy = 0\n",
    "        probabilities_map = probabilities[key]\n",
    "        for probability_key in probabilities_map:\n",
    "            probability = probabilities_map[probability_key] / sums[key]\n",
    "            if probability == 0: \n",
    "                entropy = 0\n",
    "                break\n",
    "            entropy = entropy + (probability * math.log2(probability))\n",
    "        total_entropy = total_entropy + (-entropy * (sums[key]/num_items))\n",
    "    return total_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probabilities = {'blue':{'no':3,'yes':0},'green':{'no':2,'yes':4},'red':{'no':3,'yes':3}}\n",
    "test_sums = {'blue':3,'green':6,'red':6}\n",
    "assert round (calculate_entropy(test_probabilities,test_sums,15),2) == 0.77\n",
    "test_probabilities = {'large':{'no':2,'yes':6},'small':{'no':6,'yes':1}}\n",
    "test_sums = {'large':8,'small':7}\n",
    "assert round (calculate_entropy(test_probabilities,test_sums,15),2) == 0.71\n",
    "test_probabilities = {'round':{'no':3,'yes':4},'square':{'no':5,'yes':3}}\n",
    "test_sums = {'round':7,'square':8}\n",
    "assert round (calculate_entropy(test_probabilities,test_sums,15),2) == 0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_base_entropy\"></a>\n",
    "## get_base_entropy\n",
    "\n",
    "This function calculates the entropy of the base dataset by considering only the label occurrences. \n",
    "\n",
    "* **training_data** (List): A list representing the training data, where each sublist corresponds to a data point.\n",
    "* **label_location** (int): The index representing the location of the label (class) in each data point.\n",
    "* **labels** (List): A list of unique labels present in the label column of the training data.\n",
    "\n",
    "**returns**\n",
    "The entropy value calculated for the base dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_entropy(training_data,label_location,labels):\n",
    "    base_data = []\n",
    "    BASE = \"base\"\n",
    "    for data in training_data:\n",
    "        base_data.append([BASE,data[label_location]])\n",
    "    proabilities,sums = get_probabilities(1,0,base_data,labels)\n",
    "    return calculate_entropy(proabilities,sums,len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_training_data = [['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes'], ['square', 'small', 'blue', 'no']]\n",
    "test_labels = get_labels(test_training_data)\n",
    "assert round(get_base_entropy(test_training_data,3,test_labels),2) == 0.92\n",
    "test_training_data = [['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'no'], ['square', 'small', 'blue', 'no']]\n",
    "assert round(get_base_entropy(test_training_data,3,test_labels),2) == 0\n",
    "test_training_data = [['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes']]\n",
    "assert round(get_base_entropy(test_training_data,3,test_labels),2) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pick_best\"></a>\n",
    "## pick_best\n",
    "\n",
    "This function identifies the best attribute to split the dataset based on the highest information gain. It calculates the information gain for each attribute and selects the one that maximizes the gain.\n",
    "\n",
    "* **training_data** (List): A list representing the training data, where each sublist corresponds to a data point.\n",
    "* **skips** (List): Indexes to not consider \n",
    "* **labels** (List) : A list of unique labels present in the label column of the training data.\n",
    "\n",
    "**returns**\n",
    "The index representing the location of the best attribute to split the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best(training_data,skips,labels):\n",
    "    label_location = len(training_data[0]) - 1\n",
    "    num_items = len(training_data)\n",
    "    base_entropy = get_base_entropy(training_data,label_location,labels)\n",
    "    max_attr_location,max_gain = 0,0\n",
    "    for attr_location in range(label_location):\n",
    "        if attr_location in skips: continue # skip column\n",
    "        proabilities,sums = get_probabilities(label_location,attr_location,training_data,labels)\n",
    "        entropy = calculate_entropy(proabilities,sums,num_items)\n",
    "        curr_gain = base_entropy - entropy\n",
    "        if curr_gain > max_gain: max_attr_location,max_gain = attr_location,curr_gain\n",
    "    return max_attr_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_training_data = [['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes'], ['round', 'small', 'blue', 'no']]\n",
    "test_labels = get_labels(test_training_data)\n",
    "test_skips = []\n",
    "assert pick_best(test_training_data,test_skips,test_labels) == 0\n",
    "test_skips = [0]\n",
    "assert pick_best(test_training_data,test_skips,test_labels) == 2\n",
    "test_training_data = [['round', 'large', 'green', 'no'], ['square', 'small', 'green', 'no'], ['square', 'large', 'blue', 'yes']]\n",
    "test_skips = [0,2]\n",
    "assert pick_best(test_training_data,test_skips,test_labels) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_subset\"></a>\n",
    "## get_subset\n",
    "\n",
    "This function extracts a subset of the training data where a specific attribute has a particular value. It filters the original dataset to include only the data points where the specified attribute matches the provided value.\n",
    "\n",
    "* **training_data** (List): A list representing the training data, where each sublist corresponds to a data point.\n",
    "* **attr** (string): The value of the attribute for which the subset is to be obtained.\n",
    "* **attr_location** (int): The index representing the location of the attribute in each data point.\n",
    "\n",
    "**returns**\n",
    "A subset of the training data containing only the data points where the specified attribute matches the provided value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(training_data,attr,attr_location):\n",
    "    subset = []\n",
    "    for data in training_data:\n",
    "        if data[attr_location] == attr: subset.append(data)\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_training_data = [['round', 'large', 'blue', 'no'], ['square', 'large', 'green', 'yes'], ['round', 'small', 'blue', 'no']]\n",
    "assert get_subset(test_training_data,'round',0) == [['round', 'large', 'blue', 'no'],['round', 'small', 'blue', 'no']]\n",
    "assert get_subset(test_training_data,'square',0) == [['square', 'large', 'green', 'yes']]\n",
    "assert get_subset(test_training_data,'green',2) == [['square', 'large', 'green', 'yes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id3\"></a>\n",
    "## id3\n",
    "\n",
    "This function implements the ID3 (Iterative Dichotomiser 3) algorithm, a decision tree algorithm for classification. It recursively builds a decision tree based on the provided training data and attributes.\n",
    "\n",
    "* **training_data** (List): A list representing the training data, where each sublist corresponds to a data point.\n",
    "* **attribute_names** (List): A list containing the names of attributes in the training data.\n",
    "* **skips** (List): Indexes of columns that have already been moved to in decision tree\n",
    "* **depth_limit** (int): An optional parameter limiting the depth of the decision tree. If set to 0, the function returns the most frequent label; if not provided, the tree expands until homogeneity is reached.\n",
    "* **labels** (List): A list of unique labels present in the label column of the training data.\n",
    "* **default** (Any): The default label to return if the training data is empty.\n",
    "\n",
    "**returns**\n",
    "A nested dictionary representing the decision tree. Each node in the tree is a tuple containing the attribute name, attribute index, and attribute value. The leaf nodes contain the predicted label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(training_data,attribute_names,skips,labels,depth_limit,default='no'):\n",
    "    if len(training_data) == 0: return default\n",
    "    is_homogenous,majority_label = get_majority_label(training_data,labels)\n",
    "    if is_homogenous or len(attribute_names) == len(skips): return majority_label\n",
    "    if depth_limit != None:\n",
    "        if depth_limit == 0: return majority_label\n",
    "        depth_limit = depth_limit - 1\n",
    "    best_attr_index = pick_best(training_data,skips,labels)\n",
    "    best_attr_domain = get_attr_domain(training_data,best_attr_index)\n",
    "    depth_map= {}\n",
    "    for attr in best_attr_domain:\n",
    "        subset = get_subset(training_data,attr,best_attr_index)\n",
    "        next_skips = deepcopy(skips)\n",
    "        next_skips.append(best_attr_index)\n",
    "        node = (attribute_names[best_attr_index],best_attr_index,attr)\n",
    "        depth_map[node] = id3(subset,attribute_names,next_skips,labels,depth_limit,majority_label)\n",
    "    return depth_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 1: Empty Training Data\n",
    "training_data_1 = []\n",
    "attribute_names_1 = []\n",
    "skips = []\n",
    "depth_limit_1 = 2\n",
    "labels_1 = ['no', 'yes']\n",
    "default_1 = 'no'\n",
    "assert id3(training_data_1, attribute_names_1, skips, labels_1, depth_limit_1,  default_1) == 'no'\n",
    "\n",
    "# Test Case 2: Non-empty Training Data\n",
    "training_data_2 = [['round', 'large', 'blue', 'no'],\n",
    "                    ['square', 'large', 'green', 'yes'],\n",
    "                    ['square', 'small', 'red', 'no'],\n",
    "                    ['round', 'large', 'red', 'yes'],\n",
    "                    ['square', 'small', 'blue', 'no']]\n",
    "attribute_names_2 = ['shape', 'size', 'color']\n",
    "skips = []\n",
    "depth_limit_2 = 2\n",
    "\n",
    "labels_2 = ['no', 'yes']\n",
    "default_2 = 'no'\n",
    "decision_tree_2 = id3(training_data_2, attribute_names_2, skips,labels_2, depth_limit_2, default_2)\n",
    "expected_tree_2 = {('color', 2, 'blue'): 'no', ('color', 2, 'green'): 'yes', ('color', 2, 'red'): {('shape', 0, 'square'): 'no', ('shape', 0, 'round'): 'yes'}}\n",
    "assert decision_tree_2 == expected_tree_2\n",
    "\n",
    "# Test Case 3: Non-empty Training Data with Depth Limit\n",
    "training_data_3 = [['round', 'large', 'blue', 'no'],\n",
    "                    ['square', 'large', 'green', 'yes'],\n",
    "                    ['square', 'small', 'red', 'no'],\n",
    "                    ['round', 'large', 'red', 'yes'],\n",
    "                    ['square', 'small', 'blue', 'no']]\n",
    "attribute_names_3 = ['shape', 'size', 'color']\n",
    "attr_map_3 = {'round': 0, 'square': 0, 'large': 1, 'small': 1, 'blue': 2, 'green': 2, 'red': 2}\n",
    "depth_limit_3 = 0  # Depth limit set to 0\n",
    "labels_3 = ['no', 'yes']\n",
    "default_3 = 'no'\n",
    "assert id3(training_data_3, attribute_names_3, attr_map_3,  labels_3, depth_limit_3, default_3) == 'no'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "## train\n",
    "\n",
    "This function takes training_data, attribute names, and the depth limit and returns the decision tree as a nested dictionary. If the depth is 0, a dictionary is not returned. Instead, the mode of the target values is returned (i.e., majority class). \n",
    "\n",
    "* **training_data** List[List]: The data\n",
    "* **attribute_names** List: The attribute names of the data (22 for mushroom; size, shape, and color for the lecture)\n",
    "* **depth_limit** int: The depth limit of the tree\n",
    "\n",
    "\n",
    "**returns** \n",
    "* **dt** Dict: The trained decision tree using the ID3 algorithm (entropy, information gain). It is represented as a nested dictionary. The dictionary returned for the lecture is structured as below:\n",
    "\n",
    "```\n",
    "{\n",
    "('size', 1, 'large'): \n",
    "    {('color', 2, 'blue'): 'no', \n",
    "     ('color', 2, 'green'): 'yes', \n",
    "     ('color', 2, 'red'): \n",
    "         {('shape', 0, 'round'): 'yes', \n",
    "          ('shape', 0, 'square'): 'no'}\n",
    "     }, \n",
    "('size', 1, 'small'): \n",
    "     {('shape', 0, 'square'): 'no', \n",
    "      ('shape', 0, 'round'): \n",
    "          {('color', 2, 'blue'): 'no', \n",
    "           ('color', 2, 'red'): 'yes', \n",
    "           ('color', 2, 'green'): 'no'}\n",
    "      }\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "Notice that the keys are tuples; for instance, ('size', 1, 'large') is a key. The key includes the attribute's name, column number in data, and value.\n",
    "\n",
    "\n",
    "The function currently returns a hard-coded tree. Your implementation should replace this with a tree that is learned from the data using the ID3 algorithm. You do not have to assert test `train`, but it may be worthwhile to check that it can return the tree from the lecture once your implementation is in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data, attribute_names, depth_limit=None):\n",
    "    labels = get_labels(training_data)\n",
    "    return id3(training_data,attribute_names,[],labels,depth_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_lecture = train(training_data=train_lecture, attribute_names=attribute_names_lecture, depth_limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_prediction\"></a>\n",
    "## get_prediction\n",
    "\n",
    "This recursive function uses a decision tree represented as a nested dictionary get a prediction from a record, which is a row of the data. \n",
    "\n",
    "* **record** List[]: A row of data to be predicted\n",
    "* **dt** the decision tree used to make the prediction\n",
    "\n",
    "\n",
    "**returns** \n",
    "A prediction ('yes' or 'no' for instance, from our Self Check example.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(record, dt):\n",
    "    if not isinstance(dt, dict):\n",
    "        return dt\n",
    "    else:\n",
    "        for key, value in dt.items():\n",
    "            if record[key[1]]==key[2]:\n",
    "                return get_prediction(record, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "no\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "print(get_prediction(['round','large','blue','no'], dt=dt_lecture))\n",
    "print(get_prediction(['square','large','green','yes'], dt=dt_lecture))\n",
    "print(get_prediction(['square','small','red','no'], dt=dt_lecture))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classify\"></a>\n",
    "## classify\n",
    "\n",
    "This function takes a decision tree, observations, and a labeled flag to return a list of classifications. \n",
    "\n",
    "* **dt** Dict: The decision tree as a nested dictionary\n",
    "* **observation** List[List]: a list of items, where each item is a row of the data\n",
    "* **labeled** Bool: true for labeled data\n",
    "\n",
    "\n",
    "**returns** \n",
    "* **y_hat** List: A list of classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(dt, observations):\n",
    "    y_hat = []\n",
    "    for record in observations:\n",
    "        y_hat.append(get_prediction(record, dt))   \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(classify(dt=dt_lecture, observations=test_lecture))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate\"></a>\n",
    "## evaluate\n",
    "\n",
    "This function evaluates the performance of a classifier. It takes a data set (training set or test set) and the classification result (see [classify](#classify) above and calculates the classification error rate:\n",
    "\n",
    "$$error\\_rate=\\frac{errors}{n}$$ \n",
    "\n",
    "* **y_hat** List: A list of predictions\n",
    "* **observations** List[List]: Data to be predicted (typically training or test set)\n",
    "\n",
    "\n",
    "**returns** \n",
    "\n",
    "* **error_rate** float: The error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_hat, observations):\n",
    "    errors = 0\n",
    "    ground_truth = get_answers(observations)\n",
    "    for index in range(len(y_hat)):\n",
    "        if y_hat[index] != ground_truth[index]:\n",
    "            errors = errors + 1\n",
    "    return errors / (len(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(classify(dt=dt_lecture, observations=data_lecture), observations=data_lecture))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_stats\"></a>\n",
    "## get_stats\n",
    "\n",
    "This function computes the mean and the standard deviation for a given list of observations. \n",
    "\n",
    "* **observations** List[float]: A list of observations\n",
    "\n",
    "\n",
    "**returns** (mean, standard deviation) Tuple[float,float]: tuple consisting of mean and the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(observations: List[float]) -> Tuple[float,float]:\n",
    "    mean = sum(observations) / len(observations)\n",
    "    variance = sum([(elem - mean)**2 for elem in observations]) / len(observations)\n",
    "    std_dev = math.sqrt(variance)\n",
    "    return mean, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_stats([2, 4, 4, 4, 5, 5, 7, 9]) == (5.0, 2.0)\n",
    "assert get_stats([1, 1, 1]) == (1.0, 0.0)\n",
    "assert get_stats([0]) == (0.0, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cross_validate\"></a>\n",
    "## cross_validate\n",
    "\n",
    "This function takes folds of data to `train`, `classify`, and `evaluate`.\n",
    "\n",
    "\n",
    "* **folds** List[List[List]]: The original dataset partitioned into folds (see `create_folds` above)\n",
    "* **attribute_names** int: the feature names\n",
    "* **hyperparameters** List: A list of hyperparameters to explore (depth limits for a decision tree, for instance)\n",
    "\n",
    "**returns** \n",
    "\n",
    "Nothing is returned, but for each hyperparameter setting, the function prints out the fold number and the error rate for that fold. The mean and variance is printed across folds for each hyperparameter setting. The error rates are reported in terms of percents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(folds, attribute_names, hyperparameters):\n",
    "    for hyperparameter in hyperparameters:\n",
    "        train_error, test_error  = [], []\n",
    "        error_list_train, error_list_test = [], []\n",
    "        for fold_index in range(len(folds)):\n",
    "            training_data, test_data = create_train_test(folds, fold_index)\n",
    "            tree = train(training_data=training_data, attribute_names=attribute_names, depth_limit=hyperparameter)\n",
    "            y_hat_train = classify(tree, training_data)\n",
    "            y_hat_test = classify(tree, test_data)\n",
    "            error_rate_train = evaluate(y_hat_train, training_data)\n",
    "            error_rate_test = evaluate(y_hat_test, test_data)\n",
    "            error_list_train.append(error_rate_train)\n",
    "            error_list_test.append(error_rate_test)\n",
    "            print(f\"Fold: {fold_index}\\tTrain Error: {error_rate_train*100:.2f}%\\tTest Error: {error_rate_test*100:.2f}%\")\n",
    "        print(f\"***\")\n",
    "        print(f\"Depth limit: {hyperparameter}\")\n",
    "        print(f\"\\nMean(Std. Dev.) over all folds:\\n-------------------------------\")\n",
    "        print(f\"Train Error: {get_stats(error_list_train)[0]*100:.2f}%({get_stats(error_list_train)[1]*100:.2f}%) Test Error: {get_stats(error_list_test)[0]*100:.2f}%({get_stats(error_list_test)[1]*100:.2f}%)\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\tTrain Error: 46.15%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 46.15%\tTest Error: 50.00%\n",
      "Fold: 2\tTrain Error: 46.15%\tTest Error: 100.00%\n",
      "Fold: 3\tTrain Error: 46.15%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 38.46%\tTest Error: 100.00%\n",
      "Fold: 5\tTrain Error: 50.00%\tTest Error: 0.00%\n",
      "Fold: 6\tTrain Error: 42.86%\tTest Error: 100.00%\n",
      "Fold: 7\tTrain Error: 42.86%\tTest Error: 100.00%\n",
      "Fold: 8\tTrain Error: 50.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 50.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 0\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 45.88%(3.53%) Test Error: 55.00%(41.53%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 15.38%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 30.77%\tTest Error: 50.00%\n",
      "Fold: 2\tTrain Error: 23.08%\tTest Error: 0.00%\n",
      "Fold: 3\tTrain Error: 15.38%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 23.08%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 14.29%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 21.43%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 21.43%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 28.57%\tTest Error: 100.00%\n",
      "Fold: 9\tTrain Error: 28.57%\tTest Error: 100.00%\n",
      "***\n",
      "Depth limit: 1\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 22.20%(5.59%) Test Error: 45.00%(41.53%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 15.38%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 15.38%\tTest Error: 0.00%\n",
      "Fold: 3\tTrain Error: 7.69%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 15.38%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 7.14%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 14.29%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 14.29%\tTest Error: 100.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 2\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 8.96%(6.53%) Test Error: 30.00%(40.00%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 3\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 4\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 5\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 50.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 100.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: None\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 25.00%(33.54%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_validate(folds=folds_lecture, attribute_names=attribute_names_lecture, hyperparameters=[0, 1, 2, 3, 4, 5, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pretty_print_tree\"></a>\n",
    "## pretty_print_tree\n",
    "\n",
    "This function provides a text-based representation of a decision tree that is represented as a nested dictionary. \n",
    "\n",
    "* **dt** Dict: The decision tree as a nested dictionary\n",
    "* **tab_space** Int: How much to tab successive depth levels of the resulting tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_tree(dt, tab_space):\n",
    "    for key, value in dt.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(\"  \" * tab_space + str(key[0]).upper() + \" - \" + str(key[2]) + \": \")\n",
    "            print(\"\\n\")\n",
    "            pretty_print_tree(value, tab_space+3)\n",
    "        else:\n",
    "            print(\"  \" * tab_space + str(key[0]).upper() + \" - \" + str(key[2]) + \" =====> \" + str(value))\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE - large: \n",
      "\n",
      "\n",
      "      COLOR - blue =====> no\n",
      "\n",
      "\n",
      "      COLOR - green =====> yes\n",
      "\n",
      "\n",
      "      COLOR - red: \n",
      "\n",
      "\n",
      "            SHAPE - round =====> yes\n",
      "\n",
      "\n",
      "            SHAPE - square =====> no\n",
      "\n",
      "\n",
      "SIZE - small: \n",
      "\n",
      "\n",
      "      SHAPE - square =====> no\n",
      "\n",
      "\n",
      "      SHAPE - round: \n",
      "\n",
      "\n",
      "            COLOR - blue =====> no\n",
      "\n",
      "\n",
      "            COLOR - red =====> yes\n",
      "\n",
      "\n",
      "            COLOR - green =====> no\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_lecture = train(training_data=data_lecture, attribute_names=attribute_names_lecture, depth_limit=None)\n",
    "pretty_print_tree(dt_lecture, tab_space=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <p>\n",
    "        Let's work on the mushroom data. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify the Mushrooom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "folds_mushroom = create_folds(data=data_mushroom, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\tTrain Error: 48.35%\tTest Error: 46.86%\n",
      "Fold: 1\tTrain Error: 48.31%\tTest Error: 47.23%\n",
      "Fold: 2\tTrain Error: 48.16%\tTest Error: 48.59%\n",
      "Fold: 3\tTrain Error: 48.38%\tTest Error: 46.62%\n",
      "Fold: 4\tTrain Error: 48.30%\tTest Error: 47.29%\n",
      "Fold: 5\tTrain Error: 48.30%\tTest Error: 47.29%\n",
      "Fold: 6\tTrain Error: 47.93%\tTest Error: 50.62%\n",
      "Fold: 7\tTrain Error: 48.25%\tTest Error: 47.78%\n",
      "Fold: 8\tTrain Error: 48.10%\tTest Error: 49.14%\n",
      "Fold: 9\tTrain Error: 47.93%\tTest Error: 50.62%\n",
      "***\n",
      "Depth limit: 0\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 48.20%(0.16%) Test Error: 48.20%(1.41%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 1.57%\tTest Error: 0.62%\n",
      "Fold: 1\tTrain Error: 1.48%\tTest Error: 1.48%\n",
      "Fold: 2\tTrain Error: 1.52%\tTest Error: 1.11%\n",
      "Fold: 3\tTrain Error: 1.44%\tTest Error: 1.85%\n",
      "Fold: 4\tTrain Error: 1.52%\tTest Error: 1.11%\n",
      "Fold: 5\tTrain Error: 1.46%\tTest Error: 1.60%\n",
      "Fold: 6\tTrain Error: 1.41%\tTest Error: 2.09%\n",
      "Fold: 7\tTrain Error: 1.49%\tTest Error: 1.35%\n",
      "Fold: 8\tTrain Error: 1.49%\tTest Error: 1.35%\n",
      "Fold: 9\tTrain Error: 1.39%\tTest Error: 2.22%\n",
      "***\n",
      "Depth limit: 1\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 1.48%(0.05%) Test Error: 1.48%(0.46%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.63%\tTest Error: 0.25%\n",
      "Fold: 1\tTrain Error: 0.63%\tTest Error: 0.25%\n",
      "Fold: 2\tTrain Error: 0.62%\tTest Error: 0.37%\n",
      "Fold: 3\tTrain Error: 0.56%\tTest Error: 0.86%\n",
      "Fold: 4\tTrain Error: 0.57%\tTest Error: 0.74%\n",
      "Fold: 5\tTrain Error: 0.59%\tTest Error: 0.62%\n",
      "Fold: 6\tTrain Error: 0.59%\tTest Error: 0.62%\n",
      "Fold: 7\tTrain Error: 0.59%\tTest Error: 0.62%\n",
      "Fold: 8\tTrain Error: 0.60%\tTest Error: 0.49%\n",
      "Fold: 9\tTrain Error: 0.53%\tTest Error: 1.11%\n",
      "***\n",
      "Depth limit: 2\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.59%(0.03%) Test Error: 0.59%(0.26%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.31%\tTest Error: 0.12%\n",
      "Fold: 1\tTrain Error: 0.33%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.31%\tTest Error: 0.12%\n",
      "Fold: 3\tTrain Error: 0.26%\tTest Error: 0.62%\n",
      "Fold: 4\tTrain Error: 0.31%\tTest Error: 0.12%\n",
      "Fold: 5\tTrain Error: 0.26%\tTest Error: 0.62%\n",
      "Fold: 6\tTrain Error: 0.27%\tTest Error: 0.49%\n",
      "Fold: 7\tTrain Error: 0.29%\tTest Error: 0.37%\n",
      "Fold: 8\tTrain Error: 0.30%\tTest Error: 0.25%\n",
      "Fold: 9\tTrain Error: 0.30%\tTest Error: 0.25%\n",
      "***\n",
      "Depth limit: 3\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.30%(0.02%) Test Error: 0.30%(0.21%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 4\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 0.00%(0.00%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: 5\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 0.00%(0.00%)\n",
      "\n",
      "\n",
      "Fold: 0\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 1\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 2\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 3\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 4\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 5\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 6\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 7\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 8\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "Fold: 9\tTrain Error: 0.00%\tTest Error: 0.00%\n",
      "***\n",
      "Depth limit: None\n",
      "\n",
      "Mean(Std. Dev.) over all folds:\n",
      "-------------------------------\n",
      "Train Error: 0.00%(0.00%) Test Error: 0.00%(0.00%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_validate(folds=folds_mushroom, attribute_names=attribute_names_mushroom, hyperparameters=[0, 1, 2, 3, 4, 5, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <p>\n",
    "        Let's work on the mushroom data. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the Mushroom Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ODOR - f =====> p\n",
      "\n",
      "\n",
      "ODOR - n: \n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - n =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - k =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - y =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - w: \n",
      "\n",
      "\n",
      "            HABITAT - w =====> e\n",
      "\n",
      "\n",
      "            HABITAT - g =====> e\n",
      "\n",
      "\n",
      "            HABITAT - p =====> e\n",
      "\n",
      "\n",
      "            HABITAT - l: \n",
      "\n",
      "\n",
      "                  CAP-COLOR - n =====> e\n",
      "\n",
      "\n",
      "                  CAP-COLOR - c =====> e\n",
      "\n",
      "\n",
      "                  CAP-COLOR - y =====> p\n",
      "\n",
      "\n",
      "                  CAP-COLOR - w =====> p\n",
      "\n",
      "\n",
      "            HABITAT - d: \n",
      "\n",
      "\n",
      "                  GILL-SIZE - n =====> p\n",
      "\n",
      "\n",
      "                  GILL-SIZE - b =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - b =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - r =====> p\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - h =====> e\n",
      "\n",
      "\n",
      "      SPORE-PRINT-COLOR - o =====> e\n",
      "\n",
      "\n",
      "ODOR - c =====> p\n",
      "\n",
      "\n",
      "ODOR - s =====> p\n",
      "\n",
      "\n",
      "ODOR - p =====> p\n",
      "\n",
      "\n",
      "ODOR - a =====> e\n",
      "\n",
      "\n",
      "ODOR - y =====> p\n",
      "\n",
      "\n",
      "ODOR - l =====> e\n",
      "\n",
      "\n",
      "ODOR - m =====> p\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_mushroom = train(training_data=data_mushroom, attribute_names=attribute_names_mushroom, depth_limit=None)\n",
    "pretty_print_tree(dt_mushroom, tab_space=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
